# 大数据课程

## 03 MySql数据库安装



```shell
#1、创建初始化目录
mkdir -p /iddbs;mkdir -p  /iddbs/mysql-5.7.31;mkdir -p  /iddbs/software;mkdir -p  /iddbs/scripts;mkdir -p  /dbdata;mkdir -p  /dbdata/3306;mkdir -p  /dbdata/3306/data;mkdir -p  /dbdata/3306/binlog;mkdir -p  /dbdata/3306/logs;mkdir -p  /dbdata/3306/tmp;mkdir -p  /dbdata/backup;
#2、赋权用户和用户组权限
chown -R mysql:mysql /iddbs /dbdata

#3、将mysql-5.7.31-linux-glibc2.12-x86_64.tar 上传到 /iddbs目录解压
tar -zxcf xxxx

#4、修改配置文件 3306.cfg，将3306.cfg上传到  /dbdata/3306

#5、使用 3306.cfg配置进行初始化MySQL，然后在启动mysql
/iddbs/mysql-5.7.31/bin/mysqld --defaults-file=/dbdata/3306/3306.cfg --initialize

#6、初始化后生成的临时密码查看
cat /dbdata/3306/logs/mysql-error.log |grep " A temporary password"

#7、启动MySQL数据库 需要配置环境变量
mysqld_safe --defaults-file=/dbdata/3306/3306.cfg &

#8、修改MySQL数据库root用户密码
mysql -uroot -p'f#GcuED#<7M6' -S /dbdata/3306/mysql.sock --connect-expired-password -e "alter user root@localhost identified by 'Dong@2021';flush privileges;"

#9、使用root用户登录MySQL数据库
mysql -uroot -p'Dong@2021' -S /dbdata/3306/mysql.sock  

#推荐用此模式 手工输入密码。
mysql -uroot -p -S /dbdata/3306/mysql.sock 

#给用户授权
grant all privileges on *.* to 'dong'@'%' identified by '123456';

#mysql 新设置用户或更改密码后需用flush privileges刷新MySQL的系统权限相关表，否则会出现拒绝访问，
#也可以重新启动mysql来使新设置生效。­
flush privileges;

#10、关闭数据库
mysqladmin -uroot -p'Dong@2021' -S /dbdata/3306/mysql.sock shutdown
#也可以通过
ps -ef |grep mysql
kill -9  mysql  
```

## 06 SSH免密通信

```shell
#直接登录
ssh ip 

#拷贝
scp -r /iddbs/ ip:/file


#多主机频繁拷贝和登录使用
#生成密匙，将公钥.ssh/id_rsa.pub放在需要访问的主机.ssh/authorized_keys文件中，
#.ssh和authorized_keys权限必须只有用户又写权限
ssh-keygen 

vi /etc/hosts
10.6.211.200 dongMysql01
10.6.211.201 dongMysql02
10.6.211.201 dongMysql03
#让主机和ip地址对应 只使用主机名通信就可以了
```

## 07 zookeeper集群安装

```shell
#设置几台主机免密通信

#改变主机名，需要重启
vim /etc/hostname

#上传zookeeper压缩包并解压
 

vi zookeeper/conf/zoo.cfg 
dataDir=/e3base/e3-info/zookeeper/data  #zookeeper存储数据位置，手动创建
clientPort=11001	#客户端访问的端口
server.1=dongMysql01:11002:11003		#改为对应主机名 123对应存储的myid文件内容，需要手动创建myid文件，位置在上面
server.2=dongMysql02:11002:11003		#端口为相互监听的端口
server.3=dongMysql03:11002:11003

vi zookeeper/conf/zookeeper-env.sh
export JAVA_HOME=/usr/java/jdk1.7.0_80		#配置javahome
export ZOO_LOG_DIR=/e3base/e3-info/zookeeper/logs	#日志文件夹
export ZOO_LOG4J_PROP="INFO,ROLLINGFILE"

# 配置好后可以直接scp -r zookeeper dongMysql02:/e3base/zookeeper

./zkServer.sh --help #可查看帮助

#将zkServier.sh加入环境变量
vim ~/.bash_profile
export ZOO_HOME=/e3base/zookeeper
export PATH=$ZOO_HOME/bin:$PATH
#使配置生效
source ~/.bash_profile

sh zkServer.sh start	#三台主机都执行

# 查看状态 主从
sh zkServer.sh status

# 登录到zk
sh zkCli.sh -server dongMysql03:11001 

# 查看zk目录
ls /

# 退出
quit

sh zkServer.sh stop	#停止集群
```

## 08 hadoop集群规划

```shell
#主机之间需要关闭防火墙
systemctl disable firewalld
systemctl stop firewalld
systemctl sutatus firewalld

#数据目录模拟挂载
```

## 09 hadoop配置及集群虚拟克隆



```shell
group add dong
passwd dong
useradd -m dong -g dong -d /home/dong
#查看创建的用户
cat /etc/passwd | grep dong
#查看创建的用户组
cat /etc/group | grep dong

vi hadoop/etc/hadoop/hdfs-site.xml
```

目录规划

```shell
mkdir -p  /e3base
mkdir -p   /e3base/e3-info
mkdir -p   /e3base/e3-info/hadoop
mkdir -p   /e3base/e3-info/hadoop/logs
mkdir -p   /e3base/e3-info/hadoop/nn
mkdir -p   /e3base/e3-info/hadoop/jn
mkdir -p   /e3base/e3-info/hadoop/pids
mkdir -p   /e3base/e3-info/hadoop-hdfs
mkdir -p   /e3base/e3-info/hadoop/logs/fairscheduler
mkdir -p   /e3base/e3-info/zookeeper
mkdir -p   /e3base/e3-info/zookeeper/logs
mkdir -p   /e3base/e3-info/zookeeper/data
mkdir -p   /e3base/e3-info/hive
mkdir -p   /e3base/e3-info/hive/logs
mkdir -p   /e3base/e3-info/spark
mkdir -p   /e3base/e3-info/spark/logs
mkdir -p   /e3base/e3-info/spark/tmp
mkdir -p  /data1  
mkdir -p  /data2
mkdir -p  /data3
chown  -R  dong:dong  /e3base  /data1 /data2  /data3

#/e3base 作为hadoop安装的主目录，可以自定义
#/e3base/e3-info 存储日志数据和namenode元数据的目录，可以自定义
#/data1 /data2 /data3 作为分布式文件系统存储的路径，实际生产上是独立挂载的数据盘
#mkdir -p   /e3base/e3-info/hadoop-hdfs  是hdfs存储临时文件的目录，需要修改hdfs-site.xml里的配置路径，默认是系统自带的临时文件目录，重启后会被清理
```

配置环境变量并使用source命令使之生效

```xml
export IN_HOME=/e3base
export JAVA_HOME=/home/dong/jdk1.8.0_91
export PATH=$JAVA_HOME/bin:$PATH

export ZOO_HOME=$IN_HOME/zookeeper
export PATH=$ZOO_HOME/bin:$PATH

export HADOOP_HOME=/e3base/hadoop
export PATH=$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$PATH

export HIVE_HOME=$IN_HOME/hive
export PATH=$HIVE_HOME/bin:$PATH

export SPARK_HOME=$IN_HOME/spark
export PATH=$SPARK_HOME/bin:$PATH
```



hadoop配置hdfs-site.xml

```xml
<!--设置为自己的主机名-->
		<property>
        <name>dfs.namenode.nn1.hostname</name>
        <value>dongMysql01</value>
    </property>
    <property>
        <name>dfs.namenode.nn2.hostname</name>
        <value>dongMysql02</value>
    </property>
<!--3,4,5主机，源数据同步协调作用-->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://dongMysql03:12007;dongMysql04:12007;dongMysql05:12007/drmcluster</value>
    </property>


<!-- 一些其他路径已经规划好了 --> 还没修改
   	<property>
        <name>dfs.domain.socket.path</name>
        <value>/e3base/e3-info/hadoop-hdfs/dn._PORT</value>
    </property>
```

配置core-site.xml文件

```xml
    <property>
        <name>ha.zookeeper.quorum</name>
        <value>dongMysql03:11001,dongMysql04:11001,dongMysql05:11001</value>
    </property>
```

配置hadoop-env.sh

```shell
export JAVA_HOME=/home/dong/jdk1.8.0_91

#不能设置太大，机器不行
export HADOOP_HEAPSIZE=512

#设置占用内存大小
export HADOOP_NAMENODE_OPTS="-Xmx256m -Xms256m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=12010 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false $HADOOP_NAMENODE_OPTS"
export HADOOP_DATANODE_OPTS=" -server -Xmx256m -Xms256m  -Xmn128m -XX:SurvivorRatio=1 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+CMSParallelRemarkEnabled  -XX:+UseCMSCompactAtFullCollection  -XX:+UseCMSInitiatingOccupancyOnly -XX:-DisableExplicitGC -Dhadoop.security.logger=ERROR,RFAS -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=12011 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false $HADOOP_DATANODE_OPTS"
```

修改yarn-site.xml

```xml
<!--zk-->
		<property>
        <name>yarn.resourcemanager.zk-address</name>
        <value>dongMysql03:11001,dongMysql04:11001,dongMysql05:11001</value>
    </property>
<!--resourcemanager主机-->
    <property>
        <name>yarn.resourcemanager.rm1</name>
        <value>dongMysql01</value>
    </property>
    <property>
        <name>yarn.resourcemanager.rm2</name>
        <value>dongMysql02</value>
    </property>

<!-- cpu and memory -->
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>2048</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-vcores</name>
        <value>1</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-vcores</name>
        <value>2</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>1024</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>2</value>
    </property>
```

配置yarn-env.sh

```shell
export JAVA_HOME=/home/dong/jdk1.8.0_91

export YARN_NODEMANAGER_OPTS="-Xmx256m -Xms256m -Xmn128m -XX:-UseGCOverheadLimit -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=60 -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=13015 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false ${YARN_NODEMANAGER_OPTS}"

#不能太小否则有些进程会起不来
JAVA_HEAP_MAX=-Xmx512m 

YARN_HEAPSIZE=512
```

修改fair-scheduler.xml

```xml
<!-- 修改为我们电脑所能支撑的性能 -->
    <maxResources>2048 mb, 4 vcores</maxResources>

    <queue name="default">
      <maxResources>2048 mb, 4 vcores</maxResources>
    </queue>
```

修改slaves

```xml
dongMysql03
dongMysql04
dongMysql05
```

配置mapred-site.xml

```xml
    <property>
        <name>mapreduce.jobhistory.hostname</name>
        <value>dongMysql02</value>
    </property>
```

配置mapred-env.sh

```shell
export HADOOP_JOB_HISTORYSERVER_HEAPSIZE=512
```

设置几台台主机免密通信并配置/etc/hosts

修改zookeeper 配置/e3base/zookeeper/conf/zoo.cfg 并设置dongMysql04 和 dongMysql05主机的 /e3base/e3-info/zookeeper/data/myid内容分别为2和3

```xml
server.1=dongMysql03:11002:11003		
server.2=dongMysql04:11002:11003	
server.3=dongMysql05:11002:11003
```



### 启动

```shell
#启动zkServer 在dongMysql03,04,05执行
zkServer.sh start
```



初始化namenode高可用关系

```shell
# dongMysql01执行
hdfs zkfc -formatZK
```

启动journalnode

```shell
#在dongMysql03,dongMysql04,dongMysql05 执行 
hadoop-daemon.sh start journalnode
#可以在这三台主机的/e3base/e3-info/hadoop/logs/位置下查看日志
```

初始化命名空间

```shell
#dongMysql01上执行
hdfs namenode -format

#将/e3base/e3-info/hadoop/nn/current文件同步到hadoop02
```

启动管理节点

```shell
#dongMysql01上执行 可以在log文件中查看日志,jps可以查看服务是否启动
hadoop-daemon.sh start namenode
```

启动zkfc

```shell
#在dongMysql01中启动
hadoop-daemon.sh start zkfc
```

启动备节点namenode,zkfc

```shell
hadoop-daemon.sh start namenode
hadoop-daemon.sh start zkfc
```

启动数据节点

```shell
#在hadoop03，04,05上执行,jps可以查看服务是否启动
hadoop-daemon.sh start datanode
```

启动资源管理节点

```shell
#在hadoop01,02上运行,jps可以查看服务是否启动

yarn-daemon.sh start resourcemanager
```

启动节点管理者

```shell
在dongMysql03,04,05上运行
yarn-daemon.sh start nodemanager
```

## 10 Hadoop应用案例

```shell
hdfs haadmin -getServiceState nn1
#在查看第二台主机是，报错，下面的命令是正常的，不知道为啥

yarn rmadmin -getServiceState rm2
```









## 11 Hive安装

hive的核心配置文件及启停

配置/e3base/hive/conf/hive-env.sh，将内存调小

```shell
 if [ "$SERVICE" = "metastore" ]; then
     export HADOOP_OPTS="$HADOOP_OPTS -Xms256m -Xmx512m -XX:NewRatio=12 -Xms10m -XX:MaxHeapFreeRatio=40 -XX:MinHeapFreeRatio=15 -XX:+UseParNewGC -XX:-UseGCOverheadLimit"
 fi
 if [ "$SERVICE" = "hiveserver2" ]; then
     export HADOOP_OPTS="$HADOOP_OPTS -Xms256m -Xmx512m -XX:NewRatio=12 -Xms10m -XX:MaxHeapFreeRatio=40 -XX:MinHeapFreeRatio=15 -XX:-UseGCOverheadLimit"
 fi
```

配置/e3base/hive/conf/hive-site.xml

```xml
    <!--  配置zk --> 
		<property>
         <name>hive.zookeeper.quorum</name>
         <value>dongMysql03,dongMysql04,dongMysql05</value>
     </property>

		<!-- metastore规划到dongMysql03主机 -->
		 <property>
         <name>hive.metastore.uris</name>
         <value>thrift://10.6.211.202:15001</value>
     </property>

		<!-- mysql的主机 -->
		 <property>
         <name>javax.jdo.option.ConnectionURL</name>
         <value>jdbc:mysql://10.6.211.201:3306/hivedb?createDatabaseIfNotExist=true</value>
     </property>

	
		<!-- hive的用户和密码，需要权限且不能是root用户 -->
     <property>
         <name>javax.jdo.option.ConnectionUserName</name>
         <value>hive</value>
     </property>
     <property>
         <name>javax.jdo.option.ConnectionPassword</name>
         <value>123465</value>
     </property>
```

配置/e3base/hive/conf/hive-log4j.properties，已经初始化，不需要再配置了

```shell
hive.log.dir=/e3base/e3-info/hive/logs
hive.log.file=hive.log
```

将hive的三个配置文件拷贝到其他主机

```shell
scp hive-env.sh hive-site.xml hive-log4j.properties dongMysql02:/e3base/hive/conf/
```

启动mysql服务

```shell
sh mysql-start.sh

#查看是否启动成功
sh mysql3306.sh
```

在数据库中创建索引（sql语句）

```shell
use hivedb;
create index ind_part_name_tbl_id on partitions(part_name,tbl_id);
create index ind_tbl_name on tbls (tbl_name);
create index ind_tbl_id on partitions (tbl_id);
create index ind_tbl_integer_idx on partition_keys (tbl_id,integer_idx);
create index ind_cd_integer_idx on columns_v2 (cd_id,integer_idx);
create index ind_name on dbs (name);
```

使用mysql作为hive元数据数据库，在3号机上执行



```shell
schematool -initSchema -dbType mysql
#jps可以看到RunJar进程的运行

nohup hive --service hiveserver2 2>&1 >> /e3base/e3-info/hive/logs/hiveserver2.log &
#会生成一个新的RunJar
#hive相当于启动成功了

#查看hive进程： 
ps -ef |grep hive
#查看hive端口： 
netstat -tlunp |grep 15001; 
netstat -tlunp |grep 15002;
```

### 实操实验：

```shell
#主机3登录hive
hive

#创建数据库
create database student;

#创建表
CREATE TABLE IF NOT EXISTS student.studentInfo( 
        userid INT, 
        age  INT, 
        gender STRING, 
        major STRING , 
        zipcode INT) 
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY '|' 
STORED AS TEXTFILE; 

#查看
desc studentinfo

#创建文件
vi /e3base/hive/studentInfo

#内容为
215569|22|女|电子信息
215571|23|男|电子信息
215572|22|男|电子信息
215574|24|女|电子信息
215576|22|男|电子信息
215577|25|男|人工智能
215578|22|男|人工智能
215579|22|女|人工智能
215587|23|男|人工智能
215588|23|女|人工智能
215589|24|男|人工智能
215592|22|女|人工智能

# 将数据导入表中
	use student;
	LOAD DATA LOCAL INPATH '/e3base/hive/studentInfo' OVERWRITE INTO TABLE studentInfo;
  #其中studentInfo添加信息包括：用户ID|年龄|性别|专业

# 将 u_user表中用户按照age降序排列，并查询出前5位用户信息：
select * from studentInfo u order by u.age desc limit 5 ;

# 可以使用主机4查看正在运行的任务：
hadoop job -list

# 杀掉正在运行的任务:
hadoop job -kill job_id

# 统计u_user表中不同性别的人数。
select u.gender, count(distinct u.userid) from studentInfo u group by u.gender;
```











 hive启动过程：

元数据初始化：schematool -initSchema -dbType mysql

启动metastore服务：nohup hive --service metastore -p 15001 2>&1 >> /e3base/e3-info/hive/logs/metastore.log &

启动hiveserver2服务：nohup hive --service hiveserver2 2>&1 >> /e3base/e3-info/hive/logs/hiveserver2.log &

查看hive进程： ps -ef |grep hive

查看hive端口： netstat -tlunp |grep 15001; netstat -tlunp |grep 15002;

验证hive状态：

（1）执行： hive  （2）beeline -u jdbc:hive2://dongMysql03:15002/default -n e3base







导入数据

```shell
use seu;
	LOAD DATA LOCAL INPATH '/e3base/data/dwa_v_cus_cb_charge202110.txt' OVERWRITE INTO TABLE DWA_V_M_CUS_CB_SING_CHARGE;
    select * from DWA_V_M_CUS_CB_SING_CHARGE limit 5 ;
  LOAD DATA LOCAL INPATH '/e3base/data/dwa_v_m_cus_cb_user_info202110.txt' OVERWRITE INTO TABLE DWD_M_PRD_CB_USER_INFO;
    select * from DWD_M_PRD_CB_USER_INFO limit 5 ;
    
  LOAD DATA LOCAL INPATH '/e3base/data/DWD_D_MRT_AL_CHL_ORG_202109.txt' OVERWRITE INTO TABLE DWD_M_MRT_AL_CHL_ORG;
		select * from DWD_M_MRT_AL_CHL_ORG limit 5 ;
  
  
  select * from DWD_M_MRT_AL_CHL_ORG limit 5 ;
```